{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dfe36ab",
   "metadata": {},
   "source": [
    "# Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b42c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip -q install openai agno\n",
    "# ! pip install pandas\n",
    "# ! pip install python-dotenv\n",
    "# ! pip install duckduckgo-search\n",
    "# ! pip install -U tavily-python\n",
    "# ! pip install tantivy\n",
    "# ! pip install openai newspaper4k lxml_html_clean\n",
    "# ! pip install pydantic-ai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d1c58d",
   "metadata": {},
   "source": [
    "# Load Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f7e440b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded API Key: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(dotenv_path='../backend/.env')  # Adjust if not running from 'notebooks/'\n",
    "\n",
    "\n",
    "# Access the variables\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "gmail_user = os.getenv(\"GMAIL_ADDRESS\")\n",
    "gmail_pass = os.getenv(\"GMAIL_APP_PASSWORD\")\n",
    "tavily_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Loaded API Key:\", bool(openai_key))  # Should print True if loaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd53c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from pydantic_ai.common_tools.tavily import tavily_search_tool\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from chromadb import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764b1c05",
   "metadata": {},
   "source": [
    "# Output Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16e0b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "# ---------------------------\n",
    "# Structured Output Models\n",
    "# ---------------------------\n",
    "class AnswerSource(BaseModel):\n",
    "    answer: str\n",
    "    sources: List[str]\n",
    "\n",
    "class FinalOutput(BaseModel):\n",
    "    rag: AnswerSource\n",
    "    web: AnswerSource\n",
    "    final_summary: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3fdde0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Initialize Model & Agents\n",
    "# ---------------------------\n",
    "model = OpenAIModel(\"gpt-4\")\n",
    "\n",
    "# Vector DB\n",
    "chroma_client = Client()\n",
    "collection = chroma_client.get_or_create_collection(name=\"knowledge_base\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2a0e73",
   "metadata": {},
   "source": [
    "# Team Structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43acc1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specialized Agents\n",
    "rag_agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You are a knowledge specialist. Use the RAG system to answer queries and provide sources.\"\n",
    ")\n",
    "\n",
    "web_agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You are a research specialist. Conduct web searches to answer queries and provide sources.\"\n",
    ")\n",
    "\n",
    "email_agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You are an email specialist. Draft and send emails based on provided content.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5a4f59",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966e8579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools first\n",
    "async def query_rag(ctx: RunContext[None], query: str) -> AnswerSource:\n",
    "    results = collection.query(query_texts=[query], n_results=3)\n",
    "    documents = results[\"documents\"][0]\n",
    "    sources = results[\"metadatas\"][0]\n",
    "    answer = \" \".join(documents)\n",
    "    return AnswerSource(answer=answer, sources=sources)\n",
    "\n",
    "async def send_email(ctx: RunContext[None], content: str) -> str:\n",
    "    sender_email = gmail_user\n",
    "    receiver_email = \"nayeem60151126@gmail.com\"\n",
    "    password = gmail_pass\n",
    "\n",
    "    message = MIMEText(content)\n",
    "    message[\"Subject\"] = \"AI Summary\"\n",
    "    message[\"From\"] = sender_email\n",
    "    message[\"To\"] = receiver_email\n",
    "\n",
    "    try:\n",
    "        with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465) as server:\n",
    "            server.login(sender_email, password)\n",
    "            server.send_message(message)\n",
    "        return \"Email sent successfully.\"\n",
    "    except Exception as e:\n",
    "        return f\"Failed to send email: {e}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3355e634",
   "metadata": {},
   "source": [
    "# Team Configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2988cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_lead_agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=\"Coordinate RAG and web search, summarize findings, and optionally send via email.\",\n",
    "    output_type=FinalOutput,\n",
    "    tools=[\n",
    "        query_rag,\n",
    "        send_email,\n",
    "        tavily_search_tool(api_key=tavily_key)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5e2ea2",
   "metadata": {},
   "source": [
    "# Example Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55ee4f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: \n",
      "RAG Sources: []\n",
      "Web Answer: Generative AI and large language models (LLMs) are at the center of recent advancements in AI. These LLMs, which were traditionally used for processing and understanding text, have now evolved to comprehend images and are becoming proficient in understanding speech and video data. They are now being used to handle complex logical tasks and step-by-step reasoning processes. Additionally, these models can understand diverse forms of information beyond just text. These advancements extend beyond professional settings, impacting personal lives by integrating into everyday tasks such as communication, education, and personal assistance. In the enterprise sector, LLMs are used for customer support, chatbots, internal knowledge retrieval, content generation, marketing, coding automation, and business intelligence. They can even help companies with context-aware recommendations, data insights, process optimizations, compliance, and strategic planning.\n",
      "Web Sources: ['https://www.turing.com/blog/generative-ai-llms-developments', 'https://medium.com/data-bistrot/15-artificial-intelligence-llm-trends-in-2024-618a058c9fdf', 'https://www.morganstanley.com/insights/articles/ai-trends-reasoning-frontier-models-2025-tmt']\n",
      "Final Summary: Significant advancements in AI and Large Language Models (LLMs) have been observed, with these models evolving beyond the processing and understanding of text to understanding images, speech, and video data. LLMs are now capable of handling complex logical tasks and step-by-step reasoning processes. This has made them applicable in professional settings and personal lives as they integrate into everyday tasks such as communication and education. Businesses are also leveraging LLMs for customer support, content generation, marketing, internal knowledge retrieval, and coding automation. With AI reasoning, they provide context-aware recommendations, data insights, process optimizations, compliance and strategic planning.\n",
      "Email sent successfully.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Execution Function\n",
    "# ---------------------------\n",
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    user_query = \"What are the latest developments in AI and LLMs?\"\n",
    "\n",
    "    # Run the Team Lead agent\n",
    "    result = await team_lead_agent.run(user_query)\n",
    "    output = result.output\n",
    "\n",
    "    # Display structured outputs\n",
    "    print(\"RAG Answer:\", output.rag.answer)\n",
    "    print(\"RAG Sources:\", output.rag.sources)\n",
    "    print(\"Web Answer:\", output.web.answer)\n",
    "    print(\"Web Sources:\", output.web.sources)\n",
    "    print(\"Final Summary:\", output.final_summary)\n",
    "\n",
    "    # Ask user for email confirmation\n",
    "    confirmation = input(\"Would you like to send this summary via email? (yes/no): \").strip().lower()\n",
    "    if confirmation == \"yes\":\n",
    "        email_result = await send_email(None, output.final_summary)\n",
    "        print(email_result)\n",
    "    else:\n",
    "        print(\"Email not sent.\")\n",
    "\n",
    "# Run the async main function (for notebook use)\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747bf14b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
