{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dfe36ab",
   "metadata": {},
   "source": [
    "# Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b42c60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydantic-ai\n",
      "  Downloading pydantic_ai-0.2.4-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pydantic-ai-slim==0.2.4 (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai)\n",
      "  Downloading pydantic_ai_slim-0.2.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: eval-type-backport>=0.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pydantic-ai-slim==0.2.4->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (0.2.0)\n",
      "Collecting griffe>=1.3.2 (from pydantic-ai-slim==0.2.4->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai)\n",
      "  Using cached griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: httpx>=0.27 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pydantic-ai-slim==0.2.4->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (0.28.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.28.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pydantic-ai-slim==0.2.4->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (1.31.1)\n",
      "Collecting pydantic-graph==0.2.4 (from pydantic-ai-slim==0.2.4->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai)\n",
      "  Downloading pydantic_graph-0.2.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pydantic>=2.10 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pydantic-ai-slim==0.2.4->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (2.11.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pydantic-ai-slim==0.2.4->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (0.4.0)\n",
      "Collecting fasta2a==0.2.4 (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai)\n",
      "  Downloading fasta2a-0.2.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting anthropic>=0.49.0 (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai)\n",
      "  Downloading anthropic-0.51.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: boto3>=1.35.74 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (1.37.20)\n",
      "Collecting argcomplete>=3.5.0 (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai)\n",
      "  Using cached argcomplete-3.6.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: prompt-toolkit>=3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (3.0.43)\n",
      "Requirement already satisfied: rich>=13 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (13.7.1)\n",
      "Requirement already satisfied: cohere>=5.13.11 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (5.14.2)\n",
      "Collecting pydantic-evals==0.2.4 (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai)\n",
      "  Downloading pydantic_evals-0.2.4-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: groq>=0.15.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (0.24.0)\n",
      "Collecting mcp>=1.6.0 (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai)\n",
      "  Downloading mcp-1.9.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting mistralai>=1.2.5 (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai)\n",
      "  Using cached mistralai-1.7.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting openai>=1.75.0 (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai)\n",
      "  Using cached openai-1.79.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: google-auth>=2.36.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (2.36.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (2.32.3)\n",
      "Requirement already satisfied: starlette>0.29.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from fasta2a==0.2.4->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (0.41.2)\n",
      "Requirement already satisfied: anyio>=0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pydantic-evals==0.2.4->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (4.9.0)\n",
      "Collecting logfire-api>=1.2.0 (from pydantic-evals==0.2.4->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai)\n",
      "  Downloading logfire_api-3.16.0-py3-none-any.whl.metadata (972 bytes)\n",
      "Requirement already satisfied: pyyaml>=6.0.2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pydantic-evals==0.2.4->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (6.0.2)\n",
      "Collecting rich>=13 (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai)\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from anthropic>=0.49.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from anthropic>=0.49.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (0.7.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from anthropic>=0.49.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from anthropic>=0.49.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from anyio>=0->pydantic-evals==0.2.4->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from httpx>=0.27->pydantic-ai-slim==0.2.4->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from httpx>=0.27->pydantic-ai-slim==0.2.4->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx>=0.27->pydantic-ai-slim==0.2.4->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pydantic>=2.10->pydantic-ai-slim==0.2.4->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pydantic>=2.10->pydantic-ai-slim==0.2.4->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (2.33.2)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.20 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from boto3>=1.35.74->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (1.37.20)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from boto3>=1.35.74->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from boto3>=1.35.74->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (0.11.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from botocore<1.38.0,>=1.37.20->boto3>=1.35.74->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from botocore<1.38.0,>=1.37.20->boto3>=1.35.74->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (2.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.20->boto3>=1.35.74->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (1.17.0)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from cohere>=5.13.11->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (1.10.0)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from cohere>=5.13.11->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (0.4.0)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from cohere>=5.13.11->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (0.20.3)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from cohere>=5.13.11->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (2.32.0.20250328)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.32.2->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (3.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tokenizers<1,>=0.15->cohere>=5.13.11->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (0.26.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere>=5.13.11->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere>=5.13.11->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere>=5.13.11->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (24.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere>=5.13.11->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (4.66.5)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from google-auth>=2.36.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from google-auth>=2.36.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from google-auth>=2.36.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (4.9)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.36.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (0.4.8)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from griffe>=1.3.2->pydantic-ai-slim==0.2.4->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (0.4.6)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from mcp>=1.6.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (2.6.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from mcp>=1.6.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (0.0.17)\n",
      "Collecting sse-starlette>=1.6.1 (from mcp>=1.6.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai)\n",
      "  Downloading sse_starlette-2.3.5-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: uvicorn>=0.23.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from mcp>=1.6.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (0.32.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.28.0->pydantic-ai-slim==0.2.4->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.28.0->pydantic-ai-slim==0.2.4->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (7.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.28.0->pydantic-ai-slim==0.2.4->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (3.17.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.28.0->pydantic-ai-slim==0.2.4->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (1.14.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from prompt-toolkit>=3->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (0.2.5)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pydantic-settings>=2.5.2->mcp>=1.6.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (1.0.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from rich>=13->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from rich>=13->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=13->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (0.1.0)\n",
      "Collecting starlette>0.29.0 (from fasta2a==0.2.4->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai)\n",
      "  Using cached starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python312\\site-packages (from uvicorn>=0.23.1->mcp>=1.6.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,groq,mcp,mistral,openai,vertexai]==0.2.4->pydantic-ai) (8.1.8)\n",
      "Downloading pydantic_ai-0.2.4-py3-none-any.whl (10 kB)\n",
      "Downloading pydantic_ai_slim-0.2.4-py3-none-any.whl (161 kB)\n",
      "Downloading fasta2a-0.2.4-py3-none-any.whl (14 kB)\n",
      "Downloading pydantic_evals-0.2.4-py3-none-any.whl (49 kB)\n",
      "Downloading pydantic_graph-0.2.4-py3-none-any.whl (26 kB)\n",
      "Downloading anthropic-0.51.0-py3-none-any.whl (263 kB)\n",
      "Using cached argcomplete-3.6.2-py3-none-any.whl (43 kB)\n",
      "Using cached griffe-1.7.3-py3-none-any.whl (129 kB)\n",
      "Downloading logfire_api-3.16.0-py3-none-any.whl (80 kB)\n",
      "Downloading mcp-1.9.0-py3-none-any.whl (125 kB)\n",
      "Using cached mistralai-1.7.0-py3-none-any.whl (301 kB)\n",
      "Using cached openai-1.79.0-py3-none-any.whl (683 kB)\n",
      "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading sse_starlette-2.3.5-py3-none-any.whl (10 kB)\n",
      "Using cached starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "Installing collected packages: logfire-api, griffe, argcomplete, starlette, rich, sse-starlette, pydantic-graph, openai, mistralai, fasta2a, anthropic, pydantic-ai-slim, mcp, pydantic-evals, pydantic-ai\n",
      "\n",
      "   -- -------------------------------------  1/15 [griffe]\n",
      "   -- -------------------------------------  1/15 [griffe]\n",
      "  Attempting uninstall: starlette\n",
      "   -- -------------------------------------  1/15 [griffe]\n",
      "    Found existing installation: starlette 0.41.2\n",
      "   -- -------------------------------------  1/15 [griffe]\n",
      "   -------- -------------------------------  3/15 [starlette]\n",
      "    Uninstalling starlette-0.41.2:\n",
      "   -------- -------------------------------  3/15 [starlette]\n",
      "      Successfully uninstalled starlette-0.41.2\n",
      "   -------- -------------------------------  3/15 [starlette]\n",
      "   -------- -------------------------------  3/15 [starlette]\n",
      "  Attempting uninstall: rich\n",
      "   -------- -------------------------------  3/15 [starlette]\n",
      "    Found existing installation: rich 13.7.1\n",
      "   -------- -------------------------------  3/15 [starlette]\n",
      "    Uninstalling rich-13.7.1:\n",
      "   -------- -------------------------------  3/15 [starlette]\n",
      "      Successfully uninstalled rich-13.7.1\n",
      "   -------- -------------------------------  3/15 [starlette]\n",
      "   ---------- -----------------------------  4/15 [rich]\n",
      "   ---------- -----------------------------  4/15 [rich]\n",
      "   ---------- -----------------------------  4/15 [rich]\n",
      "   ---------- -----------------------------  4/15 [rich]\n",
      "  Attempting uninstall: openai\n",
      "   ---------- -----------------------------  4/15 [rich]\n",
      "    Found existing installation: openai 1.70.0\n",
      "   ---------- -----------------------------  4/15 [rich]\n",
      "   ------------------ ---------------------  7/15 [openai]\n",
      "   ------------------ ---------------------  7/15 [openai]\n",
      "    Uninstalling openai-1.70.0:\n",
      "   ------------------ ---------------------  7/15 [openai]\n",
      "      Successfully uninstalled openai-1.70.0\n",
      "   ------------------ ---------------------  7/15 [openai]\n",
      "   ------------------ ---------------------  7/15 [openai]\n",
      "   ------------------ ---------------------  7/15 [openai]\n",
      "   ------------------ ---------------------  7/15 [openai]\n",
      "   ------------------ ---------------------  7/15 [openai]\n",
      "   ------------------ ---------------------  7/15 [openai]\n",
      "   ------------------ ---------------------  7/15 [openai]\n",
      "   ------------------ ---------------------  7/15 [openai]\n",
      "   ------------------ ---------------------  7/15 [openai]\n",
      "   ------------------ ---------------------  7/15 [openai]\n",
      "   ------------------ ---------------------  7/15 [openai]\n",
      "   ------------------ ---------------------  7/15 [openai]\n",
      "   ------------------ ---------------------  7/15 [openai]\n",
      "   ------------------ ---------------------  7/15 [openai]\n",
      "   ------------------ ---------------------  7/15 [openai]\n",
      "   ------------------ ---------------------  7/15 [openai]\n",
      "   ------------------ ---------------------  7/15 [openai]\n",
      "   ------------------ ---------------------  7/15 [openai]\n",
      "   ------------------ ---------------------  7/15 [openai]\n",
      "   --------------------- ------------------  8/15 [mistralai]\n",
      "   --------------------- ------------------  8/15 [mistralai]\n",
      "   --------------------- ------------------  8/15 [mistralai]\n",
      "   --------------------- ------------------  8/15 [mistralai]\n",
      "   --------------------- ------------------  8/15 [mistralai]\n",
      "   --------------------- ------------------  8/15 [mistralai]\n",
      "   --------------------- ------------------  8/15 [mistralai]\n",
      "   --------------------- ------------------  8/15 [mistralai]\n",
      "   --------------------- ------------------  8/15 [mistralai]\n",
      "   ------------------------ ---------------  9/15 [fasta2a]\n",
      "   -------------------------- ------------- 10/15 [anthropic]\n",
      "   -------------------------- ------------- 10/15 [anthropic]\n",
      "   -------------------------- ------------- 10/15 [anthropic]\n",
      "   -------------------------- ------------- 10/15 [anthropic]\n",
      "   -------------------------- ------------- 10/15 [anthropic]\n",
      "   -------------------------- ------------- 10/15 [anthropic]\n",
      "   -------------------------- ------------- 10/15 [anthropic]\n",
      "   -------------------------- ------------- 10/15 [anthropic]\n",
      "   -------------------------- ------------- 10/15 [anthropic]\n",
      "   ----------------------------- ---------- 11/15 [pydantic-ai-slim]\n",
      "   ----------------------------- ---------- 11/15 [pydantic-ai-slim]\n",
      "   -------------------------------- ------- 12/15 [mcp]\n",
      "   -------------------------------- ------- 12/15 [mcp]\n",
      "   -------------------------------- ------- 12/15 [mcp]\n",
      "   ---------------------------------- ----- 13/15 [pydantic-evals]\n",
      "   ---------------------------------------- 15/15 [pydantic-ai]\n",
      "\n",
      "Successfully installed anthropic-0.51.0 argcomplete-3.6.2 fasta2a-0.2.4 griffe-1.7.3 logfire-api-3.16.0 mcp-1.9.0 mistralai-1.7.0 openai-1.79.0 pydantic-ai-0.2.4 pydantic-ai-slim-0.2.4 pydantic-evals-0.2.4 pydantic-graph-0.2.4 rich-14.0.0 sse-starlette-2.3.5 starlette-0.46.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~cipy (C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cipy (C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cipy (C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "embedchain 0.1.128 requires rich<14.0.0,>=13.7.0, but you have rich 14.0.0 which is incompatible.\n",
      "fastapi 0.115.9 requires starlette<0.46.0,>=0.40.0, but you have starlette 0.46.2 which is incompatible.\n",
      "instructor 1.7.9 requires rich<14.0.0,>=13.7.0, but you have rich 14.0.0 which is incompatible.\n",
      "litellm 1.60.2 requires httpx<0.28.0,>=0.23.0, but you have httpx 0.28.1 which is incompatible.\n",
      "streamlit 1.37.1 requires pillow<11,>=7.1.0, but you have pillow 11.1.0 which is incompatible.\n",
      "streamlit 1.37.1 requires rich<14,>=10.14.0, but you have rich 14.0.0 which is incompatible.\n",
      "streamlit 1.37.1 requires tenacity<9,>=8.1.0, but you have tenacity 9.1.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# ! pip -q install openai agno\n",
    "# ! pip install pandas\n",
    "# ! pip install python-dotenv\n",
    "# ! pip install duckduckgo-search\n",
    "# ! pip install -U tavily-python\n",
    "# ! pip install tantivy\n",
    "# ! pip install openai newspaper4k lxml_html_clean\n",
    "# ! pip install pydantic-ai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d1c58d",
   "metadata": {},
   "source": [
    "# Load Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f7e440b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded API Key: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(dotenv_path='../backend/.env')  # Adjust if not running from 'notebooks/'\n",
    "\n",
    "\n",
    "# Access the variables\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "gmail_user = os.getenv(\"GMAIL_ADDRESS\")\n",
    "gmail_pass = os.getenv(\"GMAIL_APP_PASSWORD\")\n",
    "tavily_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Loaded API Key:\", bool(openai_key))  # Should print True if loaded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764b1c05",
   "metadata": {},
   "source": [
    "# Output Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16e0b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "class AnswerSource(BaseModel):\n",
    "    answer: str\n",
    "    sources: List[str]\n",
    "\n",
    "class FinalResponse(BaseModel):\n",
    "    rag: AnswerSource\n",
    "    web: AnswerSource\n",
    "    final_summary: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2a0e73",
   "metadata": {},
   "source": [
    "# Team Structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43acc1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "\n",
    "# Initialize the model\n",
    "model = OpenAIModel(\"gpt-4\")\n",
    "\n",
    "# RAG Agent\n",
    "rag_agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You are a knowledge specialist. Use the RAG system to answer queries and provide sources.\"\n",
    ")\n",
    "\n",
    "# Web Search Agent\n",
    "web_agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You are a research specialist. Conduct web searches to answer queries and provide sources.\"\n",
    ")\n",
    "\n",
    "# Email Agent\n",
    "email_agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You are an email specialist. Draft and send emails based on provided content.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3355e634",
   "metadata": {},
   "source": [
    "# Team Configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2988cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import RunContext\n",
    "\n",
    "# Team Lead Agent\n",
    "team_lead_agent = Agent(\n",
    "    model=model,\n",
    "    system_prompt=(\n",
    "        \"You are the team lead. For any user query, delegate tasks to the RAG and Web Search agents. \"\n",
    "        \"Combine their responses into a final summary. Then, ask the user if they would like to send this summary via email.\"\n",
    "    ),\n",
    "    output_type=FinalResponse\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a410dbd0",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from pydantic_ai import Agent, RunContext\n",
    "\n",
    "\n",
    "@team_lead_agent.tool\n",
    "async def send_email(ctx: RunContext[None], content: str) -> str:\n",
    "    \"\"\"Send an email with the provided content using Gmail SMTP.\"\"\"\n",
    "    sender_email = gmail_user\n",
    "    receiver_email = \"nayeem60151126@gmail.com\"\n",
    "    password = gmail_pass  # Use an app-specific password\n",
    "\n",
    "    message = MIMEText(content)\n",
    "    message[\"Subject\"] = \"AI Summary\"\n",
    "    message[\"From\"] = sender_email\n",
    "    message[\"To\"] = receiver_email\n",
    "\n",
    "    try:\n",
    "        with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465) as server:\n",
    "            server.login(sender_email, password)\n",
    "            server.send_message(message)\n",
    "        return \"Email sent successfully.\"\n",
    "    except Exception as e:\n",
    "        return f\"Failed to send email: {e}\"\n",
    "\n",
    "\n",
    "from pydantic_ai.common_tools.tavily import tavily_search_tool\n",
    "\n",
    "# Initialize the agent with Tavily tool\n",
    "team_lead_agent = Agent(\n",
    "    model=\"openai:gpt-4\",\n",
    "    tools=[tavily_search_tool(api_key=tavily_key)],\n",
    "    system_prompt=\"You are the team lead agent.\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5e2ea2",
   "metadata": {},
   "source": [
    "# Example Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ee4f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer: AI technology is constantly evolving, and progression is being made rapidly in various fields. Here are some of the latest trends as of 2022:\n",
      "\n",
      "1. Explainable AI: As more sectors are utilizing AI, the demand for transparency around how these systems reach their conclusions is growing. Researchers are developing \"Explainable AI\" that allows human users to understand and trust their decisions.\n",
      "\n",
      "2. AI in healthcare: AI is heavily used for disease detection, drug discovery, telemedicine, patient care, etc. In the wake of the COVID-19 pandemic, AI's role in managing health data and predicting patient outcomes has seen significant progress.\n",
      "\n",
      "3. GPT-3: OpenAI has built GPT-3, the latest version of their language prediction model, considered the most powerful language model to date.\n",
      "\n",
      "4. Robotics Process Automation (RPA): Companies are using RPA to automate repetitive and mundane tasks, improving productivity and efficiency.\n",
      "\n",
      "5. Quantum Machine Learning: By combining machine learning algorithms with quantum physics, researchers aim to enable faster, more complex computations.\n",
      "\n",
      "RAG Sources: ['RAG Source 1', 'RAG Source 2']\n",
      "Web Answer: 1. The introduction of more specialized LLM programs: Law schools worldwide, such as Oxford University, offer LLM programs with specialized concentrations in various legal fields like Intellectual Property Law, Environmental Law, Human Rights Law, etc. (Source: https://www.ox.ac.uk/admissions/graduate/courses/msc-law-and-finance?wssl=1)\n",
      "\n",
      "2. Increased emphasis on practical applications: LLM programs now often include practical training or job placement assistance as part of the coursework. This helps students get a feel for the real-world application of the law they study (Source: https://www.llm-guide.com/news/2017/02/law-schools-offer-practical-skills-to-llm-students).\n",
      "\n",
      "3. The development of online LLM programs: Many prestigious law schools, such as NYU, have introduced online LLM programs to provide more flexibility for students, especially for those who are already working professionals. (Source: https://www.law.nyu.edu/llmjsd/executivellm)\n",
      "\n",
      "4. Cross-disciplinary LLM programs: An emerging trend is the development of interdisciplinary LLMs, which offer students the chance to integrate knowledge from different fields. For example, the University of Law in the UK offers an LLM in Legal Technology. (Source: https://www.law.ac.uk/postgraduate/lpc/llm-legal-practice-course-lpc/)\n",
      "\n",
      "5. Increased focus on International Law: With the global nature of modern legal practice, many LLM programs have begun to emphasize international law studies. (Source: https://www.masterstudies.com/LLM/LLM-International-Law/)\n",
      "Web Sources: ['Web Source 1', 'Web Source 2']\n",
      "Final Summary: AI technology is rapidly evolving, with key developments observed in areas such as Explainable AI, healthcare applications, language prediction models like GPT-3, Robotics Process Automation, and Quantum Machine Learning. On the other hand, advancements in LLMs (Master of Laws) include the introduction of more specialized programs, increased emphasis on practical applications, the development and accessibility of online LLM programs, advent of cross-disciplinary programs, and a rising focus on International Law.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    user_query = \"What are the latest developments in AI and LLMs?\"\n",
    "\n",
    "    # Run the Team Lead agent\n",
    "    result = await team_lead_agent.run(user_query)\n",
    "    output = result.output\n",
    "\n",
    "    # Display structured outputs\n",
    "    print(\"RAG Answer:\", output.rag.answer)\n",
    "    print(\"RAG Sources:\", output.rag.sources)\n",
    "    print(\"Web Answer:\", output.web.answer)\n",
    "    print(\"Web Sources:\", output.web.sources)\n",
    "    print(\"Final Summary:\", output.final_summary)\n",
    "\n",
    "    # Ask user for email confirmation\n",
    "    confirmation = input(\"Would you like to send this summary via email? (yes/no): \").strip().lower()\n",
    "    if confirmation == \"yes\":\n",
    "        email_result = await send_email(None, output.final_summary)\n",
    "        print(email_result)\n",
    "    else:\n",
    "        print(\"Email not sent.\")\n",
    "\n",
    "# Use this in Jupyter or notebooks\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747bf14b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
